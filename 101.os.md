

# 操作系统原理 学习笔记

参考：

视频教程

操作系统原理(北京大学 ）  https://www.bilibili.com/video/av9555596

浙江大学 操作系统原理  李善平  https://www.bilibili.com/video/av13165555



书籍

[操作系统概念第七版中文版[郑扣根译]](file\操作系统概念第七版中文版.pdf)

[自己动手写操作系统](file\自己动手写操作系统.pdf)



全英文网站

https://pdos.csail.mit.edu/6.828/2014/schedule.html



## 1.1操作系统导学

主讲教师：李善平 季江民 寿黎但

授课32学时  实验16学时

预修课程： C语言程序设计语言 数据结构  计算机组成原理



多看书，看懂书

理解-》质疑-》否定



## 1.2操作系统引论

### 操作系统是什么？

操作系统是管理计算机硬件的程序，为应用程序提供基础，并且充当计算机硬件和计算机用户的中介



操作系统的两大目标

​	执行用户程序，并且更易于解决用户问题

​	更便于使用计算机系统



1、从计算机系统组成观点：

​	操作系统是系统软件

​	计算机系统组成  

​		软件  应用软件 系统软件

​		硬件 输入、输出设备  存储器（内存） 中央处理器



2、从资源管理程序观点：

​	操作系统是系统资源的管理者

​	操作系统是系统资源管理程序，它用于控制和管理计算机系统的硬件和软件资源



​	计算机系统资源

​		软件：程序、数据  硬件： IO设备  存储器 处理器

​		操作系统模块：  文件系统  设备管理  存储器管理  处理器（CPU、进程）管理



3、从软件分词、扩充机器的观点：

​	操作系统是扩充裸机的第一层系统软件



4、从服务用户的观点：

​	操作系统是用户和计算机硬件之间的接口

​		系统提供的接口有两累

​			命令级接口：提供了一组键盘或鼠标命令

​			程序级接口：提供了一组系统调用System Calls，即os中功能，供用户程序和其他程序调用



5、内核Kernal --  the one program running at all times on the computer (all else being application  programs)

​	在全时运行的一个程序



### 操作系统定义

操作系统是一组有效控制和管理计算机系统的硬件和软件资源，合理地组织计算机工作流程以及方便用户的程序组合。

​		有效：系统效率和资源利用率高

​		合理：公平、不公平则会产生死锁或者饥饿

​		方便：提供良好的用户界面、编程接口



计算机硬件系统结构

​	主机型：这类计算机以存储器为中心，CPU和各种通道都与存储器相连

​			以CPU和内存为核心

![](os_images\host_base.jpg)

​	总线型：微型计算机是以总线为纽带构成计算机系统，中央处理器、存储器、IO设备都挂载在总线

​		驱动程序，管理IO设备

![](os_images\bus_structure.jpg)





### 中断

中断是指CPU对系统中发生的异步事件的相应，异步事件是无一定时序关系的随机发生的事件



发生中断时正在执行的程序的暂停点称为中断断点

处理器暂停当前程序转而处理中断的过程称为中断响应

中断处理结束之后恢复原来程序的执行被称为中断返回

一个计算机系统提供的中断源的有序组合一般被称为中断字，这是一个逻辑结构，在不同的处理器有着很不相同的实现方式



中断一般可以分为硬件中断和软件中断两大类

硬件中断又可以分为硬件故障中断、输入输出中断和外部中断

软件中断（异常）又可以分为程序中断（例如定点操作数溢出，地址越界、虚拟内存管理中缺页等）和访管中断（trap陷入）

​	访管中断是用户程序在运行中请求操作系统为其提供服务而执行一条方管指令所引起的中断，又称为软件中断，系统调用。访问中断是进程所期待的，他是主动发起的中断，其他几种中断不是运行进程所期待的，它属于强迫性中断事件。



现代操作系统是中断驱动的 An operating system is interrupt driven



### 特权指令和非特权指令

特权指令：不允许用户程序中直接使用的指令。例如IO指令，设置时钟、设置寄存器等指令都是特权指令



非特权指令：用户程序中所使用的指令





### 两种运行状态

用户态 user model  ： 执行用户程序时

内核态 kernel model：执行操作系统程序时



![](os_images\kernel_to_user.jpg)





#### 内核态和用户态的区别

内核态

​	能够访问所有系统资源，可以执行特权指令，可以直接操作和管理硬件设备

​	操作系统内核程序运行在内核下

​	使用内核栈



用户态

​	只能访问属于它的存储空间和普通寄存器，只能执行普通命令

​	用户程序以及操作系统核外服务程序运行在用户态下

​	使用用户栈





QA：普通寄存器是什么？



### 操作系统特征

​	并发性

​		并行 ： 指两个或多个事件在同一时刻发生

​		并发：指两个或多个在同一时间间隔内发生

​	共享性 Sharing

​	虚拟性Virtual

​	异步性 Asynchronism



​	其他特征

​		微内核结构

​		宏（单）内核结构

​		多线程  多核

​		对称处理机分布式操作系统

​		面向对象设计



### 操作系统功能部件

​	进程管理 Process Management

​	主存管理 Main Memory Management

​	文件管理 File Management

​	I/O系统管理  I/O System Management

​	二级储存器管理  Secondary Management

​	网络处理  Networking

​	保护系统  Protecting System

​	命令解释系统 Command-Interpreter System



### 操作系统类型

按功能分（早期）

​	批处理系统 Batch System

​	分时系统 Time Sharing System

​	实时系统 Real-Time System

按同时使用系统的用户数和系统能同时运行的进程数分成：

​	单用户、单进程系统 DOS Windows 3.1

​	单用户、多进程系统 OS/2、Windows 7

​	多用户、多进程系统  Linux 、Windows Server

按计算机系统（硬件）操作系统分成

​	微机操作系统 MS-DOS Windows系列 OS/2 SCO UNIX 、Linux等

​	网络操作系统 Unix 、Linux、Windows 2003/2008/2012 server

​	分布式操作系统

​	主机（mainframe）操作系统：AIX、HP-Unix、Linux

​	嵌入式操作系统

​	传感器节点操作系统 Sensor Node Operating Systems

​	智能卡操作系统 Smart Card Operating System

​	智能手机操作系统



Windows的历史沿革

![](os_images\windows_history.jpg)



Windows操作系统产品线

![](os_images\windows_product.jpg)



Unix大家庭

![](os_images\unix_family.jpg)



QA：

什么是GNU

各种开源协议有什么区别？

http://www.ha97.com/833.html



### 什么是Linux

Linux指的是Linux内核

Linux操作系统指的是GNU/Linux系统(基于Linux的GNU系统)

​	Linux系统的组成：内核，C库、编译器、工具集和系统的基本工具、各种硬件设备驱动程序 X Windows系统，登录程序，各种应用软件包括字处理软件、图形处理软件

​	Linux系统（发行版）：GNU软件28%+Linux 内核3%+其他部件。---www.gnu.org

Linux是一种类Unix的操作系统，Linux克隆了Unix，但不是Unix

Linux是遵守GNU的GPL协议的软件



超级计算机

​	

手持系统

​	个人数字助理 PersonalDigital Assistants (PDAs) Cellular telephone(手机)

​	嵌入式系统Embedded System

​	智能手机操作系统 IOS Android Symbian Windows Phone

计算机应用领域

几种主流嵌入式操作系统

​	嵌入式Linux 

​		RT-Linux

​		XLinux

​		红旗嵌入Linux

​	VxWorks

​	QNX

​	Windows CE

​	uC/OS

​	Palm OS

智能手机操作系统

​	IOS Android Symbian Windows Phone

​		

## 1.3操作系统结构

### 操作系统服务

用户接口 ： 

​		命令行接口  CLI

​		图形用户接口 GUI

​		批处理Batch

程序执行  调入一个程序进入内存并运行之的系统能力

I/O操作   由于用户程序不能直接执行I/O操作，操作系统必须提供完成I/O操作的手段

文件系统操纵 程序能够读、写、创建和删除文件

通信  运行的进程间再同一计算机或由网络连接的不同系统中交换信息。通过共享存储器或消息传递实现

出错检测：通过探测CPU与内存硬件中，在I/O设备中 或在用户程序中的错误，确保正确运算

资源分配：把资源分配给多个用户或多个同时运行的作业

记账：跟踪和记录用户对资源的使用，用于账单和统计

保护： 确保对资源的访问均在控制中



操作系统与用户接口

​	命令接口 Command Interface

​	程序接口 Program Interface （系统调用）



命令接口

​	命令行用户接口、文本界面、图形用户接口

命令行用户界面 Command User Interface CUI

​	键盘输入 DOS Linux UNiX

图形用户界面 Graphic User Interface GUI

​	鼠标输入

​	MacOS OS/2 Windows Linux等

程序接口

​	系统调用（System Calls) 、API 应用程序接口

QA：系统调用和API的区别？

系统调用就是一种特殊的接口。通过这个接口，用户可以访问内核空间。系统调用规定了用户进程进入内核的具体位置。

api 就是应用程序接口，是一些预定义的函数。跟内核没有必然的联系。

一个api可能会需要一个或多个系统调用来完成特定功能。通俗点说就是如果这个api需要跟内核打交道就需要系统调用，否则不需要。





### 系统调用

系统调用提供了进程和操作系统之间的接口

​	这些调用通常以汇编语言指令的形式提供

​	有些语言（C、C++和Perl）已经取代了汇编语言而直接用于系统编程



向操作系统传递参数通常有三种方法

​	通过寄存器来传递参数，参数数量可能比寄存器多
​	将参数存放在内存的块或表中，并将块的地址作为参数传递给寄存器   指针 
​	把参数放在堆栈中，并通过操作系统弹出堆栈 不限制所传递参数的数量或长度	



系统调用是内核向用户进程提供服务的唯一方法，应用程序调用操作系统提供的功能模块（函数）。

用户程序通过系统调用从用户态切换到内核态，从而可以访问相应的资源。

这样做的好处是：

​	为用户控件提供一个硬件的抽象接口，使编程更加容易

​	有利于系统安全

​	有利于每个进程度运行在虚拟系统中，接口统一由利于移植



系统调用的类型

​	进程控制 结束、中止、装入、运行、创建、终止进程等

​	文件管理 创建文件、删除文件、打开、关闭文件等

​	设备管理 请求设备、释放设备、读、写、重定位设备等

​	信息维护  读取时间或日期、设置时间或日期等

​	通信   创建、删除通信连接、发送、接受消息、传递状态信息



应用编程接口（API）其实是一组函数定义，这些函数说明了如何获得一个给定的服务；而系统调用是通过软中断向内核发出一个明确的请求，每个系统调用对应一个封装例程（wrapper routine，唯一的目的就是发布系统调用），一些API应用了封装例程。

API还包含各种编程接口，如：C库函数

OpenGL编程接口等

系统调用的实现是在内核完成的，而用户态的函数是在函数库实现的



应用程序                          C库                                           内核

调用printf  -》 C库中的printf  C库中的write -》sys_write() 系统调用

printf有一部分运行在 用户态下，一部分运行在 内核态下





### 操作系统的设计

​	操作系统设计有着不同于一般应用系统设计的特征

​		复杂程度高

​		研制周期长

​		正确性难以保证  

​			最早的Unix是1400行代码，Windows xp有4000万行代码、fedroa core有2亿行代码，Linux kernel 3.1 有1700万行代码



解决途径：

​	良好的操作系统结构

​	先进的开发方法和工程化的管理方法（软件工程）

​	高效的开发工具



操作系统的设计考虑

​	功能设计：操作系统应具备哪些功能

​	算法设计：选择和设计满足系统功能的算法和策略，并分析和估算其效能

​	结构设计：选择合适的操作系统结构

按照系统的功能结构和特性要求，选择合适的结构、使用相应的结构设计方法将系统逐步的分解，抽象和综合。使操作系统结构清晰、简单、可靠、易读、而且使用方便、适用性强



几种常见的操作系统结构

​	简单结构  MS-DOS 利用最小的空间提供最多的功能 

![](os_images\ms-dos_structure.jpg)

​	层次化结构  

​			分层法的主要优点是模块化。选择了分层，这样每层都能利用底层的功能、操作和服务。

​			分层效率比较差

![](os_images\unix_structure.jpg)

​	单（宏）内核结构

​			宏内核 ，与微内核想法，宏内核是构建系统内核的传统方法。在这种方法中，内核的全部代码、包括所有子系统（如内存管理、文件系统、设备驱动程序）都打包到一个文件中。内核的每个函数都可以访问内核中所有其他部分。如果编程不小心，很可能导致源代码出现复杂的嵌套。

​	微内核

​		这种方法将所有非基本部分从内核移走，并将它们当做系统级程序和用户级程序来实现。

​		用户之间采用消息传递的方式来通信

​		优点：

​			易于扩展 

​			易于提升OS至一个新的体系结构 

​			更可靠 

​			更安全

​		缺点：

​			用户控件

​			效率低 与内核空间的通信代价较高  2个用户程序需要通过内核空间来通信

![](os_images\windows_kernel.jpg)

​	模块（Module）

​		许多现在操作系统实现内核模块（kernel Modules）

​			用面向对象的方法

​			内核的组成部分相互分离

​			任务之间的交互通过已知的接口来实现

​			每个模块在内核中是按照需要可装载的

​	模块类似于分层，但模块更具有灵活性

​		Linux Solaris Mac OS





​	虚拟机

​		虚拟机采用分层的方法，将物理硬件和OS内核统一看做为硬件。

​		虚拟机提供了于基本硬件相同的接口

​		通过利用CPU调度和虚拟内存技术，操作系统能创建一种幻觉、以至于进程认为有自己的处理器和自己的虚拟内存

​		物理计算机共享资源以创建虚拟机

​			CPU调度能共享出CPU造成一种每个用户都有自己的处理器的感觉

​			假脱机和文件系统能提供虚拟读卡机和虚拟行式打印机

​			一个普通的用户分时终端提供虚拟机操作员终端的功能

​	VMWare VirtualBox Microsoft Virtual PC

​		优缺点：

​				通过完全包含系统资源，虚拟机提供了一个坚实的安全屋

​				虚拟机允许进行系统开发而不必终端正常的系统操作

​				但虚拟机概念很难提供真实的硬件效果

![](os_images\virtual_machine.jpg)





## 2.1进程概念

李善平



![](os_images\cpu_io_process.jpg)

所有程序的执行都是CPU、I/O 交替执行   所以CPU达不到100%

所有程序输入、输出必须有一个



![](os_images\idea_muti_task.jpg)



历史原因：IO设备闲 无所谓

60年代的CPU很大，占地，水、电、空调，所以希望cpu利用率高，保证资源高效运转

一个操作系统执行了多个程序，为描述不同程序，诞生了进程



为什么不能沿用“程序”，为什么叫“进程”？

同一程序有不同的数据

不同程序有相同的数据



Process -》 a program in execution ; 在执行中的程序

​			process execution must progress in sequential fashion



进程三个维度   执行中的程序

1、执行什么程序维度

2、处理什么数据

3、描述状态维度 



Process include

​	program counter 当前执行位置

​	Stack   伴随的数据

​	data section  伴随的数据





### 内存中的进程Image实例

C语言编译后会生成不同的数据段  进程的映像

![](os_images\memory_image.jpg)



局部变量  进入 stack   ，执行完毕后退出 

共享变量、全局变量、静态变量  其他的公共数据段

malloc 动态申请内存空间  进入 heap



### 进程控制块 (PCB) 

Process Control Block 



进程通常跟以下信息关联

Process state    5种状态

Program number 进程号 不重复 正整数

Program counter   程序计数器  中央处理器中的寄存器，用于指示计算机在其程序序列中的位置

CPU registers  通用的寄存器

CPU scheuling infomation  CPU调度 依赖数据 上百字节

Memory-management infomation  所有和内存相关的变量 上百字节

Accounting infomation   记账信息 打开文件个数 占用cpu时间 占用内存等

I/O status infomation   所有设备的运行状态信息

#### 

本质是一种结构 比较复杂 CPU调度 依赖

每个进程都有一个pcb，一对一关系   几千字节  尽量小 驻留在内存

共享信息不要放PCB ，PCB只有独占信息



内存访问速度是纳秒级（10的-9次方），硬盘的访问速度是微秒级（10的-3次方）



![](os_images\pcb_example.png)

proce









![](os_images\process_status.jpg)

​	



### 进程状态

进程执行过程中，变化着状态

new   起始状态 进程被创建 

ready  就绪状态  进程准备就绪，等待分配一个CPU来解释执行

waiting 等待状态 进程等待某个事件发生   等待IO  等待进程间通信

running 执行状态   进程的代码正在解释 CPU工作

terminated  终止状态 进程被终止执行



### 进程调度队列

Job quene   等待进入计算机系统的待处理任务

Ready quene  进程就绪队列  驻留内存，准备就绪，等待CPU

Device quene 等待I/O设备的进程



等待队列 等待的资源不一样 按不同资源划分队列

![](os_images\ready_io_quene.png)

进程一经创建，即在这些对垒直接迁移，直至被终止



![](os_images\process_migration.png)



### 进程上下文切换 （Context Switch）

CPU任何时候只能为一个进程服务

当CPU转向为另外一个进程服务时，有雨CPU内部资源有限，它必须保存原有（转换前）进程的状态、装入待服务（转换后）进程的状态，也即“进程上下文切换”

状态 指寄存器、标志位、堆栈等当前值

上下文切换时间是一种额外开销（overhead），因为期间CPU不对用户进程做直接有益的事

上下文切换时间决定于CPU硬件支持力度



进程为了快速处理，希望变量放置寄存器，或内存中

[寄存器为什么比内存快？](http://www.ruanyifeng.com/blog/2013/10/register.html)

![](os_images\process_context_switch.png)





## 2.2 进程操作与进程通信

进程操作

### 进程创建

​	父进程创建若干子进程：后者再创建其子进程：与此类推，构成了反应传承关系的一颗进程树



子进程的资源

​	子进程共享父进程的所有资源

​	子进程共享父进程的部分资源

​	子进程不从父进程共享资源，重新独立申请



执行代码的执行顺序

​	父进程和子进程并发执行

​	父进程在子进程执行期间等待，待子进程执行完毕后才恢复执行余下代码

![](os_images\fork_child.png)





![](os_images\unix_fork.png)



### 进程终止

进程终止语义之一 子进程执行完最后一条执行后，要求操作系统将自己杀出(exit)，语义动作含：

​	子进程穿点数据给父进程（通过父进程的wait操作）

​	子进程的资源被操作系统收回



进程终止的语义之二 父进程终止子进程的执行（about），终止原因可能是：

​	子进程超额使用系统资源

​	早前交给子进程执行的任务，过期无效了



如果父进程终止了，它的子进程怎么办？

​	有些操作系统把这些子进程也全部终止



### 进程间合作

独立进程不会影响其他进程的执行，也不会影响

合作进程影响其他进程、或者受其影响

进程间合作是必须的，带来的好处

​	共享信息

​	加速（计算）执行任务

​	模块化

​	方便调用、等等。。。



### 进程间通信的方法

signal

管道

共享内存

消息传递



生产者进程生成信息，存储在缓冲区，供消费者进程消费

​	unbounded-buffer 缓冲区的容量无限

​	bounded-buffer 缓冲区的容量有限  一般都有限

![](os_images\bounded_buffer.png)



### Interprocess Communication (IPC)

send 发送消息给邮件服务器A

receive 从邮件服务器A接收消息



### 同步通信 VS 异步通信

同步通信   TCP协议  传输安全

​	发送操作send：发送进程等待，直至接受进程确认消息

​	接受操作receive：接收进程等待，直到有个消息到达



异步通信 UDP协议  性能好

​	发送操作send：发送进程发出消息后立即返回，不理会消息是否送达

​	接受操作receive：接收进程执行一次接收动作，要么有一条有效消息，要么收到空消息



​	

## 2.3线程

举例从fork 看线程 

![](os_images\fork_thread.png)

https://baike.baidu.com/item/fork/7143171

fork 返回两次



### 线程的定义

程序执行代码有动态的轨迹，不同于静态程序代码的排序 有跳转，有循环 有判断

提出线程 反应程序运行的轨迹

参考红线 黄线





![](os_images\thread_1.png)











![](D:/github/go_tech/os_images/threads_3.png)





### 线程的优势：

1、有效表达程序运行的线索

2、多线程 资源共享切换开销小，共享代码 公共数据 文件等

3、多线程对多CPU、多核利用比较好



线程相对于进程的优势



多线程 起源于90年代

90年代的Windows 多线程支持比较好

Unix 70年代   只有进程的概念

在Linux上，从内核角度而言，基本没有什么线程和进程的区别，都是进程。一个进程的多个线程只是多个特殊的进程他们虽然有各自的进程描述结构，却共享了同一个代码上下文。在Linux上，这样的进程称为轻量级进程Light weight process。





进程的上下文切换需要很多资源

设计TCB  Thread Control Block



### 用户级线程 User Threads

线程管理（创建、资源申请、调度、通信等）由user-level threads library 一手包办，不靠OS内核

举例，Three primary thread libraries

Java threads

POSIX pthread

Win32 thread



### 用户级线程 对应 内核线程 模型

![](os_images\thread_4.png)



这种模型将多个用户级线程映射到一个内核级线程，构成一组对应关系

操作系统运行环境里，可以存在很多组

举例

​	Linux

​	GNU Portable Threads 即GNU pth

凡是不支持线程的OS内核，都可以使用这个模型









用户态不能访问内核态的数据

内核线程  用户线程



### 线程管理相对于进程管理，带来的新问题？

fork 、exec操作的语义有变化

撤销线程（Thread cancellation）

Singal handing

Thread pools

Thread specific data

Scheduler activations

。。。





## 2.4 CPU调度

引入多程序设计，目的是地淘计算机资源利用率，尤其是CPU利用率（CPU utilization）

CPU密集 I/O密集的循环

进程的执行，呈现出CPU运行和I/O等待的交替循环

CPU密集型，I/O密集型



### CPU调度器  Scheduler

CPU调度器的使命

​	从内存中一堆准备就绪的进程中（就绪队列的就绪进程），选取一个进程

​	将CPU分配给该进程

后者也可以由dispatcher完成



![](os_images\cpu_scheduler.png)

Scheduler 在内核



### CPU调度器的操作时机

1、某一进程从执行状态转为等待状态  非抢占式调度 

2、某一进程从执行状态转为就绪状态   抢占式调度

3、某一进程从等待状态转为就绪状态   抢占式调度

4、某一进程终止   非抢占式调度

。。。

调度时机不限于此4种情况

非抢占式调度  进程自动交出CPU，引起新一轮的CPU调度

抢占式调度



CPU调度器决定了将CPU分配给谁。后续操作就是CPU调度器将CPU控制器移交给该进程。操作内容通常包括

​	上下文切换

​	从内核态转移至用户态

​	跳转至用户程序中PC寄存器所指示的位置

分配延迟（Dispatch latency）-CPU 分配器暂停前一进程，启动后进程所经历的时间



### CPU调度器追求指标

CPU利用率 CPU utilization
吞吐率 Throughput   单位时间内完成执行的进程数
周转时间 Turnaround time  执行某一进程所消耗的CPU累计时间    
​		第一次进入就绪队列开始，到进程结束 包括等待时间、CPU执行时间
等待时间 Waiting time  某一进程等待在就绪队列里面的累积时间
响应时间 response time   某一进程从发出调度请求，到其得到CPU调度器响应，其间所经历的时间
		

### CPU调度算法

#### First Come，First Served （FCFS）Scheduling

先来先服务

![](os_images\cpu_scheduling_1.png)

CPU每次只能执行一个指令 所以有先后顺序

![](os_images\cpu_sheduling3.png)

#### Shortest-Job-First （SJF） 

最短作业有限算法

算法要求：进入就绪队列的进程预告需要多长CPU时间才能完成本次执行

算法思想：选取就绪队列中，需要CPU时间最短的进程

![](os_images\cpu_scheduling_sjf.png)

![](os_images\cpu_scheduling_sjf2.png)

SJF是最优算法 

两种SJF策略比较

​	非抢占式 一旦CPU分配给了某个进程，就不能抢过来，除非该进程主动放弃CPU（CPU burst cycle结束，或者进程转去做IO操作）

​	抢占式 除了非抢占式的，其他都是抢占式

​	当一个进程进入就绪队列，如果他的CPU时间小于当前拥有CPU的进程剩余预估时间，前者抢占后者的CPU，此算法称作Shortest-Remaining-Time-First （SRTF）

SJF算法有致命缺陷 To Be Count  算不出 burst time



#### HRN （highest response Ratio Next)

HRN = （ W + T ) /  T 

W代表等待时间



#### 优先权算法

每个进程都有一个优先数，（priority number），通常是整型数

选取就绪队列中，优先权最高的进程（假设最小优先数=最高优先权）

​	Preemptive 高优先权的进程到达时引起调度

​	Nonpremptive 高优先权的进程到达时不触发一次调度

当优先权定义为进程需要的CPU时间时，SJF算法就是优先权法

![](os_images\cpu_priority.png)





Issue：进程饥饿，优先权较低的就绪进程可能永远得不到CPU

Solution=Aging思想-就绪进程等在就绪队列里的时间，折算叠加到进程优先权。因此 等待在就绪队列里的进程，其优先权单调递增



#### 轮转法（Round Robin ，RR）

每个就绪进程获得一小段CPU时间（时间片，time quantum）通常 10ms-100ms

时间片用毕，这个进程被迫交出CPU，重新挂回到就绪队列

当然，进程也在时间片用毕前其Burst Cycle结束，也主动交出CPu

假设n个就绪进程，时间片q，每个就绪进程得到1/n的CPU时间、任何就绪进程最多等待(n-1)q单位时间

![](os_images\cpu_scheduling_rr.png)

两次p3不需要上下文切换

​	Issue：引起上下文切换

![](os_images\cpu_scheduling_rr2.png)

![](os_images\cpu_scheduling_rr2.png)

平均周转时间通常优于SJF

响应时间一定优于SJF

性能分析

​	q large =》 FCFS

​	q small=》上下文切换开销太大，q必须远远大于上下文切换时间



轮转法、优先权法都是常用的算法



### 调度算法的优化

多层队列（Multilevel Queue）

把就绪队列拆分几个队列

例如：

​	要求交互的进程、在前台队列

​	可以批处理的进程、在后台队列。每个队列都有自己的调度算法

​	例如 前台就绪队列-RR

​		后台就绪队列-FCFS

![](os_images\cpu_muti_scheduling.png)



设计多层队列

​	就绪进程进入队列时选择哪层队列

CPU怎么在队列间分配

​	固定优先权法。例如，先前台队列，再后台队列

​	时间片办法。例如，80%的CPU时间给前台队列，20%的CPU时间给后台进程



多层反馈队列

​	进程可以在队列中迁移

​	Q0 用RR算法，时间片8ms

​	Q1用RR算法，时间片16ms

​	Q2用FCFS算法

![](os_images\cpu_muti_quene.png)

设计多层反馈队列

​	1、队列个数

​	2、每层队列有自己的调度算法

​	3、一个算法、将就绪进程升级至高层次队列

​	4、一个算法、将就绪进程降级至低层次队列

​	5、一个算法、决定当一个就绪进程入就绪队列时，去哪层



### 实时调度

硬实时系统-调度机制能够确保一个关键任务在给定的时间点前完成

软实时计算-调度机制尽量给与关键任务最高优先级，尽量在预定时间点前完成



### 调度算法评估

确定模型法（Deterministic modeling）采用实现设定的特定负荷，计算在给定负荷下每个算法的性能

排队模型 （Queueing models) 编程实现改算法，观察期执行情况仿真



## 3.1进程同步-临界区问题

进程同步（Process Synchronization）之（Critical Section Problem)  难度大

单cpu  多进程  进程、线程正常情况下可以独立运行  但需要考虑异常情况

#### 根本原因：

1个cpu要为多个进程服务，

对共享数据的并发访问、可能导致数据不一致

确保数据一致性，是个合理的要求，它需要一个机制，以保障合作进程们有序地进行

以生存者-消费者为例，设计一个整型变量count，总是极力缓冲区被占用的单元总数，count的初始值为0，当生产者进程注入一个单元数据时，count增1，当消费者进程消费掉一个单元数据时，count减1

![](os_images\BoundedBuffer1.png)

![](os_images\boundedbuffer1_in.png)



![](os_images\boundedbuffer1_out.png)

![](os_images\product_consumer0.png)

![](os_images\product_consumer2.png)

![](os_images\product_consumer3.png)

![](os_images\product_consumer4.png)



Race condition(竞争)  若干进程并发访问并且操作共享数据的特殊情形。共享数据的最终稳定值取决于最后完成操纵的那个进程

为避免race condits，并发进程必须同步（Synchronized）







临界区是修改共享数据的代码

#### 临界区问题 （the critical-section problem)

假设n个进程竞相访问共享数据的情形

每一个进程存在一段代码，称作为临界区(critical section)，进程就是通过这段代码访问了共享数据（share data)

其他代码段没有访问共享数据

这n个进程中，至少存在一个以上的进程甚至修改了搞那个像数据



![](os_images\ljq_simplify_frame.png)



#### 临界区问题解决方案的简化框架

互斥 （Mutual Exclusion)  

​		如果进程Pi正在临界区执行，那么其他任何进程均不允许再他们的临界区中操作

空闲让进（Progress） 

​	条件：如果没有进程处于它的临界区，并且

​				某些进程申请进入其临界区

​	那么 ：只有不在remainder sections的进程，才能参与能否进入临界区的选举，并且

​				这个选举不允许无限期（indefinitely）推迟

有限等待（Bounded Waiting），

​			某一进程从其提出请求，至他获准进入临界区的这段时间里，其他进程进入他们的临界区的次数存在上限

​				假设进程都各自都在持续运行

​				不考虑N个进程之间的相对执行速度





## 3.2临界区互斥软件实现算法

#### Algorithm 1  单标志法

核心思想：设置一个公共整形变量turn,用于指示被允许进入临界区的进程编号。若turn = 0, 表示允许P0进入临界区。

定义两个进程共享数据

int turn 并且取初值 turn = 0

turn = i => 进程P，可以进入临界区

进程Pi  

```
do{
	while(turn != i);//不做操作
		critical section  //临界区
	turn = j;
		remainder section  //其他代码段
}while(1);
```

进程Pj 

```
do{
	while(turn != j);//不做操作
		critical section  //临界区
	turn = i;
		remainder section  //其他代码段
}while(1);
```

满足Mutual Exclusion，但不满足 Progress  为什么？



当P0把钥匙给P1后，如果P1不进去，这时候如果P0想再进去，手里就没有钥匙，无法进入，违背空闲让进原则。



参考：https://www.kancloud.cn/hanghanghang/os/116761

https://www.jianshu.com/p/f25a813a75de



## 3.3临界区互斥硬件实现算法

CPU制造者为临界区问题提供硬件支持，体现原子操作



方法一、**中断屏蔽法**（效率很低，不好）

单处理架构--利用“关中”途径

关中后当前执行的代码段（临界区）不会被强占

关中法再多处理器架构中太低效，不解决问题

进程在进入临界区之前先执行”关中断”质量来屏蔽掉所有中断。进程完成临界区的任务后，在执行”开中断”执行将中断打开。



方法二、**硬件指令方法（TestAndSet指令）**

一个指令完成 TestAndSet

```
boolean TestAndSet(boolean *target)
{
	boolean rv = *target;
	*target = TRUE;
	return rv;
}
```

为每个临界资源设置一个s，看成一把锁。

若s值为0(开锁状态)，则表示每页进程访问该锁对应的临界资源;

若s的值为1(关锁状态)，则表示该锁对应的临界资源已被某个进程占用。

**具体代码**

```
while TS (&lock)	        //只要处在关锁状态就不断循环等待，**违反让权等待**

;

访问临界区;                 //临界区

lock=FALSE;                //退出区
```

方法三、**swap指令**

设置一个全局变量lock，lock=0时，空闲，反之，有进程。

每个进程设置一个局部变量key，只有当lock==0并且key==1时，进程才能进入临界区。

进入临界区后，执行swap指令，lock=1,key=0。

退出临界区时，将lock的执行置为0。

**具体代码**

```
key = true;				//初始化key
do{
	swqp(&lock,&key);
}while(&key);	        	        		//执行完了swap之后才能进入
	进入临界区;
lock = FALSE;                  //退出的时候将lock置为0
```



使用TestAndSet 和 Swap 似乎都不能满足Bounded Waiting 条件 转嫁用户处理



## 3.4信号量（Semaphore)

信号量的概念是由荷兰计算机科学家艾兹赫尔·戴克斯特拉（Edsger W. Dijkstra）发明

信号量S是整型变量

信号量S只允许两个标准操作： wait() 和signal()   或者发明人称之为P操作 通过、V操作 释放

称为V（signal()）与P（wait()） 

实现

wait操作

```
wait(S){
	value--;
	if(value<0){
		add this process to waiting queue
		
		block();//使cpu 执行sche操作
	}
}
```



signal操作

```
wait(S){
	value++;
	if( value <= 0 ){
		remove this process P from waiting queue
		
		wakeup(P);
	}
}
```



进程的临界区必须符合如下框架

```
Semaphore S; //初始值为1
do {
	wait(S);
		Critical Section;//临界区
	signal(S);
		remainder section;
}while(1);
```



信号量解决一般性进程同步问题

​	假设要求：执行进程Pi的A之后，才允许执行进程Pj的B

​	定义信号量flag，初始值为0

​	代码框架

​		Pi ->  A -> signal（flag)

​		Pj -> wait(flag)  -> B



复杂的同步问题  多个信号量 



## 3.5经典同步问题

#### 生产者消费者问题

​	生产者消费者问题是最著名的同步问题，描述一组生产者（p1…pm）向一组消费者(c1…Cq)提供消息，他们共享一个有界缓冲池，生产者向其中投递消息，消费者从中得到消息

​	假设缓存池中有n的缓冲区，每个缓冲区放一个消息。由于缓冲池是临界资源。它只允许一个生产者投入消息，或者一个消费者从中取出消息。即生产者之间、生产者与消费者之间，消费者之间必须互斥使用缓冲池。所以必须设置互斥信号量mutex，它代表缓冲池资源，它的数值为1

​	生产者和消费者二类进程之间应满足下列二个同步条件

​		只有在缓冲池中至少有一个缓冲区已存入消息后，消费者才能从中提取消息，否则消费者必须等待

​		只有缓冲池中至少有一个缓冲区是空时，生产者才能把消费者放入缓冲区，否则生产者必须等待

​	为了满足第一个同步条件，设置一个同步信号量full，它代表的字眼是缓冲池满，它的初始值为0，它的值为n时整个缓冲池满

​	为了满足第二个同步条件，设置另一个同步信号量，empty，它代表的资源是缓冲区空，它的初始值是n，标识缓冲池中所有缓冲区空

![](os_images\producer_comsumer.png)

#### 读者写者问题

​	一个数据集（如文件）如果被多个进程所共享

​		某些进程只要求读数据集内容，成为读者

​		一些进程则要求修改数据集内容，成为写者

​		几个读者可以同时读数据集，而不需要互斥

​		一个写者不能和其他进程（不管是写着或读者）同时访问些数据集，它们之间必须互斥

​	信号量及变量设置

​		写者和写者及读者需要互斥，用互斥信号量wrt表示，初始值为1

​		readcount变量来记录读者数，初值为0

​		由于readcount是读者间共享变量，属于临界资源，它也需要互斥，设置互斥信号量mutex 初值为1

​	![](os_images\reader_write.png)



#### 哲学家进餐问题

5个哲学家围绕一张圆桌而坐，桌子上放5支筷子，每两个哲学家之间放一支

哲学家的动作包括思考和进餐，进餐时需要同时拿起他左边和右边的两支筷子，思考时则同时将两支筷子放回原处

如何保证哲学家的动作有序进餐？如，不出现相邻这同时要求进餐，不出现有人永远拿不到筷子

![](os_images\chopstick.png)

为防止死锁可采取的措施：

​	最多允许4个哲学家同时坐在桌子周围 【 5个进程1个等待 4个中至少一个是运行的】

​	仅当一个哲学家左右两边的筷子都可用时，才允许他拿筷子 【and信号量 一次申请多个信号量】

​	给所有的哲学家编号，奇数号的哲学家必须首先拿起左边的筷子，偶数号的哲学家则反之

​	【奇数号的左边和偶数号的右边是同一个筷子，防止死锁】

​	为避免死锁，把哲学家分成三种状态，思考、饥饿，进食，并且一次拿到两只筷子，否则不拿

​		【类似2】



​	每个哲学家拿起第一根筷子一定时间后，若拿不到第二根筷子，就放下【从程序运行角度不可行】

例题分析：

​	1、6个进程共享某一临界资源，则互斥信号量的取值范围是？

​		A 0-1 B 0~6 C 0~-5 D 1~-5

​	2、对信号量S执行P（wait）操作后，使进程进入等待队列的条件是？

​		A  S.value < 0  B S.value <= 0

​		C  S.value > 0  D S.value >= 0	

​	3、操作系统在使用信号量解决同步与互斥问题中，若P（wait）、V（signal）操作的信号量初始值为2，当前值为-3，则表示有 ？ 等待进程。

​		A 0个  B 1个 C 2个 D 3个

​	4、设有4个进程共享一程序段，而每次最多允许2个进程进入该程序段，则信号量的初值是 ？ 

​	A  4 B 2 C 1 D 0

​	5、下列哪一个问题只包含进程互斥问题？

​	A 田径场上的接力比赛  【同步】

​	B 两个进程都要使用打印机

​	C 一个生产者和一个消费者通过一个缓冲区传递产品 【同步】

​	D 公共汽车上司机和售票员的协作  



​	6 在9个生产者，6个消费者共享容量为8个缓冲器的生产者-消费者问题中，互斥使用缓冲器的信号量mutex的初始值为？

​	A 1 B 6 C 8 D 9

​	7 有一个计数信号量，若干个进程S进行了28次P操作和18次V操作后，信号量S的值为0，然后又对信号量S进行了3次V操作，请问此时有多少个进程等待在信号量S的队列？

​	A 2 B 0 C 3 D 7

​	8、假设一个正在运行的进程对信号量S进行了P（wait）操作后，信号量S的值变为-1，此时该进程将？

​	A 转为等待状态 B 转为就绪状态 C 继续运行 D 终止



​	1 D  2 A 3 D 4 B 5B 6 A  7 B 8 A

 



参考：https://www.cnblogs.com/kiplove/p/6745335.html



## 4.1死锁的概念

死锁，指多个进程因竞争资源而造成的一种僵局，若无外力作用，这些进程将永远不能再向前推进

Example 1

​	系统有两个磁带设备

​	进程P1和P2各战友一个磁带设备并且实际需要两个磁带

Example 2

​	信号量A，B初始化为1

​		P0   wait(A)  wait(B)

​		P1  wait(B)  wait(A)

![](os_images\deadlock1.png)

一个顶点的集合V和边的集合E：

​	V被分为两个部分：

​		P={P1,P2….Pn} P:含有系统中全部的进程

​		R={R1,R2….Rn} R:含有系统中全部的资源

​	请求边：P1->R1  进程到资源的边

​	分配边：R1->P1  资源到进程的边

![](os_images\process_allocation.png)









## 4.2死锁处理

## 5.1 内存管理基本概念

基本概念和背景



#### 连续区内存分配

非连续区内存分配  页式内存管理、页表结构、段氏内存管理  示例Inter i386



程序必须装入内存后，才能（以进程为单位）被CPU解释、执行

CPU能够直接访问的，只有主存、寄存器

访问寄存器需要1个CPU时钟周期，很快    时钟频率评定CPU性能的重要指标 

访问主存需要许多时钟周期，或者需要若干机器周期

Cache位于主存、寄存器之间  一级Cache 二级Cache 三级Cache

![](os_images\compiiler.png)

C或C++编译器将源代码 转成 汇编源码

汇编语言程序翻译成二进制的机器代码  Object Module

多个Object Module 连接起来 转换为可执行文件

![](os_images\compiler2.png)



#### Assemble任务

​	把符号指令翻译成二进制指令

​	把标号（labels）翻译成二进制的地址

​	处理伪指令（pseudo-ops)

区别于编译，它基本是one-to-one的翻译

产生的目标程序（Object file）添加了

​	Text段：代码

​	Data：初始化了的全程变量

​	BSS段：未初始化的全程变量



#### 二进制的地址在操作系统的说明

​	操作系统访问的内存空间是地址空间或者逻辑地址空间

​	逻辑地址空间有2个地址限定的，基地址（base）寄存器和界限（limit） 寄存器共同划定逻辑地址空间

​	基地址寄存器  最小的地址值

​	界限寄存器	 整个进程可以达到的空间范围大小

​	![](os_images\base_limit.png)



程序执行的过程中发生

#### 指令和数据的地址绑定（Binding）

​	源程序地址通常为符号形式，compiler将其绑定（映射）在可重定位的地址（例如：“从本模块开始的第14字节”）：Linkage editor/loader 将其映射为绝对地址，例如“74014”。

​	指令和数据的地址绑定通常发生在3个阶段

​		编译时绑定：如果代码、数据的存放首地址已知，编译阶段即可确定绝对地址。如果首地址变更，则需要重新编译

​		装入时绑定：如果代码、数据的存放首地址未知，编译阶段生成可重定位地址，装入时才确定绝对地址

​		执行时绑定：如果允许进程在执行时迁移代码、数据，那么地址绑定也在执行时进行。需要硬件装置支持其地址映射（e.g.，基地址寄存器和界限寄存器）



#### 逻辑地址空间 vs 物理地址空间

​	区别于物理地址空间的各种逻辑地址空间，是OS得以管理内存的必要条件

​		逻辑地址-CPU产生的地址，也成为虚地址

​				逻辑地址-非物理的各种地址标记包括符号名，包括编译、汇编、连接、装入操作产生的地址

​		物理地址-内存单元接收到的地址。也就是说，“浮现“在地址总线的地址，以二进制形式表达。



#### 存储管理单元（MMU）

存储管理单元（Memory-Management Unit，MMU）是CPU内部的硬件装置，其功能是将虚拟地址（或逻辑地址）转换成物理地址

例如一种简单的MMU策略，在用户进程将逻辑地址送往地址总线前，MMU将重定位寄存器（relocation register）的值，加到这个逻辑地址

用户进程只能处理逻辑地址，它无法获取真正的物理地址



基于重定位寄存器的动态重定位（Dynamic relocation）

![](os_images\cpu_dynamic_relocation.png)



#### 动态连接（Dynamic Linking）

进程即将用到的代码段，不被预先连接到程序，只有到真正被调用的时刻才连接

需要动态连接库（Linux的.so，或者Windows的.dll）的配合

设计一小段代码，成为存根（stub)。

当真正调用到该段代码时，通过stub定位该段连接库代码，或者从外部装入内存



#### 动态装入（Dynamic Loading)

进程即将用到的子程序，不被预先装入，只有到真正被调用的时刻才装入内存

这样，进程本次运行中没有调用的子程序，就不会被装入内存

更有效的利用了内存空间

不需要操作系统特别的支持



#### 交换（Swapping）

进程映像暂时传输至后备存储空间保存（换出，swap out），需要（执行）时再装入内存（换入，swap in）。称为交换，一般由硬盘实现

后备存储空间

快速

大容量

直接访问机制（direct access）

交换操作结合CPU调度算法，使得及时换出低优先级的进程，让高优先级的进程装入、执行

![](os_images\cpu_swap.png)



大部分交换时间用于传输。传输时间与交换数据量成正比

交换的思想或者变种，频频见诸于UNIX，Linux、Windows等

系统只要保障就绪队列里的就绪进程全部驻留内存。其他进程映像可以被换出

#### 在存储管理中，覆盖和交换技术所要解决的是什么问题？各有什么特点？

答：覆盖技术和交换技术是两种扩充内存的技术，覆盖技术主要用于早期的操作系统中，而交换技术在现代操作系统中仍有较强的生命力。

覆盖：一个程序不需要把所有的指令和数据都装入内存，而是将程序划分为若干个功能相对独立的程序段，按照程序的逻辑结构让那些不会同时执行的程序段共享同一块内存区。这样使用户感觉到内存大了，从而达到内存扩充的目的。要求程序员提供一个清晰的覆盖结构，这对程序员的要求较高。

交换：先将内存某部分的程序或数据写入外存交换区，然后再从外存交换区中调出指定的程序或数据到内存中来并让其执行的一种内存扩充技术。交换完全由操作系统实现，它不要求程序员做特殊的工作，整个过程对程序员是透明的。交换主要是进程或作业之间进行，而覆盖则主要在同一个作业或同一个进程内进行。



#### 存储管理基本思想

​	y = f(x)

​	x为逻辑地址，y为物理地址

​	存储管理算法的评估和比较

​		硬件支持，Hardware Support

​		性能，Performance

​		碎片，Fragmentation

​		重定位，Relocation

​		交换，Swapping

​		内存共享，Memory sharing

​		内存保护，Memory protection



## 5.2 页式内存管理

#### 	页式内存管理是一种非连续的分区 

​	进程并不要求逻辑地址必须是连续的

​	把物理空间等分成长度一致的数据块，称作”页帧“（frames），操作系统对空闲页帧进行统一管理

​	把逻辑空间等分成长度一直的数据库，称作”页“（pages），并且与页帧长度相等

​	通常，页长（也就是页帧长度）是2的幂次，取512字节与8192字节之间的数值

![](os_images\logic_test2.png)

假设逻辑地址空间2的m次方，页长P为2的n次方

CPU提供的逻辑二进制地址addr区分为两个部分

​	页号(p)：p=addr/P。作为下标查询页表（page table）中目标单元，该单元包含对应于物理空间的页帧的基地址。

​	页内偏移量(d)： d=addr%P。该地址在对应页帧内部的偏移位置



![](os_images\cpu_address.png)

![](os_images\cpu_address2.png)

#### 页式内存管理（续）

OS负责监控所有空闲页帧

若进程需要n页逻辑空间，OS分配n个空闲页帧给它，装入代码和数据

OS分配页表需要的物理空间，布置好页表（决定了f函数）

页式内存管理存在Internal fragmentation问题  进程未必使用页长个字节的内存 

![](os_images\cpu_memory.png)



#### 如何实现页表？

页表必须驻留内存。为什么？ 存寄存器性能好，但是寄存器有限

页表基地址寄存器Page-table base register（PTBR）指向页表的首地址

页表长度寄存器Page-table length register（PTLR）表示页表占用的空间长度



访问一个数据/地址，需2次内存访问！

1次访问页表，1次访问数据/地址本身

解决2次内存访问问题 ，需要借助硬件 translation look-aside buffers（TLBs） 关联存储器

![](os_images\cpu_tlb.png)



![](os_images\cpu_tlb.png)



#### 有效访问时间 Effective Access Time

​	设TLB的查询时间 = n单位时间

​	假设内存访问周期为1微秒

​	命中率（Hit ratio）

​	成功地在TLB取得页号的百分率：

​	命中率与TLB的单元总数有关

​	设命中率m

​	有效访问时间（EAT） EAT=（1 + n ) m + ( 2 + n )( 1 - m )  = 2 + n - m



#### 内存保护

在进程页表的每个页表项中，为每个页设置一个保护位 Valid-invalid bit

页表项的”有效-无效“位

​	有效 表示该页面在进程的逻辑地址空间范围内，因此是合法页面

​	无效 表示该页面不在进程的逻辑地址空间范围内 

![](os_images\cpu_page.png)



#### 共享页面

​	共享代码

​		只读（可重入）代码只需要一份，供若干进程共享（i.e.. 文本编辑器，编译器，窗口系统）

​		对所有进程来说，共享代码必须位于逻辑地址空间的相同位置

​	进程自有代码和数据

​		进程各自拥有一份

​		为自有代码、数据分配的页面，可以分布在进程逻辑地址空间的任意位置

![](os_images\memory_share_page.png)



假定某页式管理系统中，主存为128KB，分成32块，块号为0、1、2、3、。。。31：某作业有5块，其页号为0、1、2、3、4，被分别装入主存的3、8、4、6、9块中。有一逻辑地址为[3,70]。试求出相应的物理地址（其中方括号中的第一个元素为页号，第二个元素为页内地址，按十进制计算），并画图说明地址变换过程。

![](os_images\cpu_share.png)



## 5.3 段式内存管理

这是一种顺应用户视角的内存管理机制

程序一定是有许多代码、数据组成。”段“是自然的逻辑单元，例如：

​	main program

​	procedure

​	function

​	method

​	object

​	local variables .global variables

​	common block

​	stack

​	symbol table .arrays

![](os_images\user_memory.png)

一个逻辑地址划分成两部分： 段浩 、段内偏移量

段表（segment table）-以段号为索引下标、将其映射至二维的物理地址

段表项内容包括

​	基地址（base）-记录该（段）在物理内存的首地址

​	界限（limit）-记录该”段“）的长度	

段表基地址寄存器（Segment-table base register STBR）指向内存中段表的首地址

段表长度寄存器Segment-table length register STLR）记录程序总段数，也表示段表项的总数

合法的段号 s 必须满足  s<STLR

![](os_images\cpu_segment.png)



![](os_images\cpu_segment2.png)

#### 段式管理机制的分析

内存保护

​	每个段表项都有保护位：

​		有效位（1位），有效位=0=》无效段

​		特权为（2位），read/write/execute

内存分配

​	段的长度可变（区别于页），内存分配面临dynamic storage-allocation问题

​	first fit/best fit/worst fit/etc

​	碎片，external fragmentation

重定位

​	可以动态重定位

​	借助段表实现

内存共享

​	以 段 为最小单位，支持进程间代码共享

​	进程必须给与共享段以相同的段号



![](os_images\cpu_memory3.png)



![](os_images\cpu_memory4.png)



## 6.1 虚拟存储思想

CPU+内存运行程序 0-(2G-1)  进程数量

先讨论实存管理，再讨论虚拟内存管理 

实存管理 ， 逻辑地址 、物理地址完全分离    只要映射就ok

fffffff0 BIOS 启动时用到的内存

逻辑地址：可执行文件装入内存的地址  二进制地址 CPU内部指令附带的地址（间接寻址）

物理地址：只有浮现在内存芯片外面地址总线上面的地址，出CPU

CPU  通过 地址总线、数据总线、控制线  和内存相连



源代码经过编译、汇编、连接、装入，都是逻辑地址

操作系统 介入  逻辑地址和物理地址的转换    函数运算

物理空间是块，逻辑空间是页  页帧（frame）

管理cpu的资源 GB MB KB   逻辑地址  物理地址



#### 理解虚拟存储思想

逻辑空间可以独立于物理空间

观察进程对于物理空间的需求

​	cpu只需要一小部分的代码（请求CPU执行的代码部分）驻留内存

​	进程的逻辑空间可以远大于（分配给它的）物理空间【只加载一部分代码、用到的指令】

​	于是、物理空间被更多的进程共享



#### 虚拟存储思想有诸多利好

实现虚拟存储思想，可以用诸多途径

​	按需调页（Demand paging）是一种比较流畅的实现策略

​	Demand segmentation 是另一种策略







## 6.2 按需调页

CPU指令 含内存访问 即访问该内存地址所在页面，称作页面引用（reference）

存在3种可能

​	页面已经装入内存，有对应页帧

​	=》CPU完成操作

​	非法的页面调用

​	=》abort

​	合法引用，但是页面不在内存  【Demand paging解决这个问题】

​	=》把页面装入内存 





![](os_images\mem_swap_in_out.png)

每个进程都有页表，对应页表项,设计一个“有效位”，a vilid-invild bit 

​	页面驻留内存

​	进程非法访问该页面、或者、页面不在内存



初始化，所有“有效位”都设置成1

CPU执行指令，访问内存单元时，一旦读到某个页表项，其“有效位”是i =》 page fault 缺页



![](os_images\cpu_page3.png)



1、2 cpu完成

3、4、5、6 内核态，操作系统完成



第一次引用某页面，对应页表项的“有效位”为i，引起缺页终端，操作系统响应这个终端

操作系统查找内核的数据结构，判断

​	它是非法引用=》abort

​	它是合法引用A，但是页面不在内存

​	操作系统查找内核的数据结构，罩保护一个空闲页帧，把页面从外存换入至该空闲页镇更新内核的数据结构，更新进程吃页表把进程页表中（该页面）页表项的“有效位”重置为v

​	缺页中断程序返回，重新执行引擎缺页中断的那条指令



当且仅当需要该页面时，才把它调入内存

​	Less ，I/O操作

​	Less，内存需求

​	Faster，响应  装入内存少，所以响应快

​	More，用户数



Lazy swapper

​	从不换入这个页面，除非有进程真的访问这个页面

​	Swapper that deals with pages in a paper





## 6.3 页面置换

Page Replacement

![](os_images\cpu_page4.png)



页面置换-在内存中找出某个逻辑页面，把它换出。需考虑

​	页面置换算法    

​	性能的影响-选中的页面置换算法，使之引起的缺页中断次数最少

​			磁盘操作  内存操作  寄存器操作

由于程序执行的不可知性，同一页面可能会装入多次 





#### 按需调页策略的性能分析

​	设缺页率(Page Fault Rate),0<=p<=1.0

​	if p = 0 ,没有缺页

​	if p = 1，每次页面引用总引起缺页



​	有效访问时间，Effective Access Time （EAT）

EAT= （1-p）x内存访问时间 + px（缺页中断处理开销 + 内存换出时间+页面换入时间+重新执行指令的开销）



设内存访问直接 = 200 纳秒 ns

设 缺页处理平均时间 = 8 毫秒  8ms

EAT = (1 - p) * 200 + p (8 毫秒)

​		 = （1-p）*200 + p * 800000

​		= 200 + p* 7999800

假设1000次页面引用会引起一次缺页中断，则EAT= 8.2微妙

EAT比正常的内存访问慢 约 40倍



#### 页面置换基本流程

​	缺页中断相应，先确定逻辑页面在交换区的位置

​	需要一个空闲页帧

​		如果找到空闲页帧，就选它了

​		如果找不到空闲页帧，调用页面置换算法选择一个“牺牲者”页帧，换出位于该页帧的页面

​	将目标页面换入至（刚腾空的）空闲页帧。更新页表等数据结构

​	返回到引起中断的进程。重新执行引起中断的指令

​	

#### 页面置换中一个技巧

​	设计利用modify（dirty） bit减少页面传输的开销

​	换出页面时判断：该页面装入后，没有被修改过，就不需要换出。可以直接丢弃。因为交换区里有它的备份

​	只有被修改过的页面，才有必要换出，也就是更新交换区的备份



分析页面置换算法

追求最低的缺页率

​	评估方法：让算法相应一串特定的内存引用（引用串，reference string），累计其缺页次数

​	后续算法讨论中，统一使用引用串 1，2，3，4，1，2，5，1，2，3，4，5

![](os_images\cpu_page5.png)





#### First-In-First-Out(FIFO)算法

![](os_images\cpu_page6.png)



![](os_images\cpu_page7.png)

![](os_images\cpu_page8.png)



#### Optimal 算法

置换掉最长时间不被引用的页面  

1，2，3，4，1，2，5，1，2，3，4，5

![](os_images\cpu_page9.png)



#### Least Recently Used (LRU)算法

1，2，3，4，1，2，5，1，2，3，4，5

![](os_images\mem_lru.png)



![](os_images\mem_lru_2.png)



LRU算法如何获知多长时间没引用？

利用计数器实现

​	每个页表项带一个计数器

​	每次引用页面时，页表项的计数器更新为当时的时钟值

​	调用置换算法时，选取计数器最早的页面，换出

利用堆栈实现-设计双向链表维护一个堆栈 

​	引用某页面时

​	将该页面移动至栈顶

​	页面置换时，不需要搜索，选取页面

![](os_images\mem_lru_3.png)



#### 近似LRU算法

First chance 算法

引用位（Reference bit）

每个页表项设计1位，引用位初始值=0

页面被访问时，引用位被置1

需要置换页面时，总是选取引用位为0的页面（如果存在这样的页面）近似算法不规定所有引用位为0的页面顺序



Second change 算法 也称clock算法

​	也需要引用位

​	需要置换页面时，（顺时针顺序）考察下一页面。如果引用位是0，则选中

​	如果其引用位=1  

​		引用位被置0

​		留在内存，这次不选它

​	考察下一页面（按照顺时针顺序），重复上述程序判断引用位



计数Counting 算法

每个页面附着一个计数器，计数器记录对改页面的引用次数

LFU算法，计数器最小的页面被选中、换出

MFU算法，计数器最大的页面被选中。基于这样的假设：计数器最小的页面可能刚刚装入内存，因此还来不及引用



![](os_images\mem_lru_4.png)









## 6.4页帧分配和系统抖动

## 6.5 教学示例

## 7.1文件系统基本概念

## 7.2目录、文件共享与保护  

## 7.3文件系统实现

## 7.4 外存分配方法 

## 7.5 教学示例

## 8.1 大容量存储结构

## 8.2 磁盘调度

## 8.3 磁盘管理和RAID结构

## 9.1 IO设备访问方式和类型

## 9.2 操作系统内核的IO子系统

## 9.3 复习课







[Linux探秘之用户态与内核态](https://www.cnblogs.com/bakari/p/5520860.html)